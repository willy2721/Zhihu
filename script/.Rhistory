stop_word <- unique(c(stop_word, toTrad(stopwordsCN())))
# Add response time
data$response_time <- time_transform(data)
# Add segmented questions and answers
data$ans_seg <- sapply(data$ans, function(x) paste(segmentCN(x), collapse = ' '))
data$ans_seg_vec <- sapply(data$ans, function(x) segmentCN(x))
data$q_seg <- sapply(data$question_combined, function(x) paste(filter_segment(seg_worker[x], stop_word), collapse = ' '))
# Add number of characters, words, and percentage of stop words
data$n_char <- char_count(data)
data$n_word <- word_count(data)
data$n_stop <- stop_word_count(data,stop_word)
data$per_stop <- stop_word_percentage(data)
# Add sentiment score
data$senti_score <- senti(data)
# Add tf_idf
ans_tfidf <- by(data, data$question_title, tf_idf_score)
data$ans_tfidf <- unlist(ans_tfidf)
# Add cluster
#data <- get_cluster_feature(data)
head(data,20)
# Global variables
data <- tbl_df(read_csv("~/dsR/final/data/current_event.csv")) %>% na.omit()
#data <- data[1:50, ]
# Add tf_idf
ans_tfidf <- by(data, data$question_title, tf_idf_score)
# Clean entire datum
#data <- full_clean(data)
#data <- subset(data, data$ans_upvote_num != 0)
data <- text_filter(data)
#Reorder the data
data <- data[order(data$question_title),]
# Get stop words
data$question_combined <- paste(data$question_title, data$question_detail)
document <- c(unique(data$question_combined),unique(data$ans))
stop_word <- get_stop_word(document)
stop_word <- unique(c(stop_word, toTrad(stopwordsCN())))
# Add response time
data$response_time <- time_transform(data)
# Add segmented questions and answers
data$ans_seg <- sapply(data$ans, function(x) paste(segmentCN(x), collapse = ' '))
data$ans_seg_vec <- sapply(data$ans, function(x) segmentCN(x))
data$q_seg <- sapply(data$question_combined, function(x) paste(filter_segment(seg_worker[x], stop_word), collapse = ' '))
# Add number of characters, words, and percentage of stop words
data$n_char <- char_count(data)
data$n_word <- word_count(data)
data$n_stop <- stop_word_count(data,stop_word)
data$per_stop <- stop_word_percentage(data)
# Add sentiment score
data$senti_score <- senti(data)
# Add tf_idf
ans_tfidf <- by(data, data$question_title, tf_idf_score)
library(readr)
library(dplyr)
library(jiebaR)
library(tidytext)
library(fpc)
library(cluster)
library(rJava)
library(tm)
library(SnowballC)
library(slam)
library(XML)
library(RCurl)
library(Matrix)
library(tmcn)
library(Rwordseg)
source('~/dsR/final/script/zhihu_utility.R')
source('~/dsR/final/script/zhihu_count.R')
source('~/dsR/final/script/zhihu_senti.R')
source('~/dsR/final/script/zhihu_tfidf_score.R')
#source('~/dsR/final/script/zhihu_tf_idf.R')
#source('~/dsR/final/script/zhihu_cluster.R')
# Global variables
data <- tbl_df(read_csv("~/dsR/final/data/current_event.csv")) %>% na.omit()
#data <- data[1:50, ]
# Clean entire datum
#data <- full_clean(data)
#data <- subset(data, data$ans_upvote_num != 0)
data <- text_filter(data)
#Reorder the data
data <- data[order(data$question_title),]
# Get stop words
data$question_combined <- paste(data$question_title, data$question_detail)
document <- c(unique(data$question_combined),unique(data$ans))
stop_word <- get_stop_word(document)
stop_word <- unique(c(stop_word, toTrad(stopwordsCN())))
# Add response time
data$response_time <- time_transform(data)
# Add segmented questions and answers
data$ans_seg <- sapply(data$ans, function(x) paste(filter_segment(seg_worker[x], stop_word), collapse = ' '))
data$ans_seg_vec <- sapply(data$ans, function(x) filter_segment(seg_worker[x], stop_word))
data$q_seg <- sapply(data$question_combined, function(x) paste(filter_segment(seg_worker[x], stop_word), collapse = ' '))
# Add number of characters, words, and percentage of stop words
data$n_char <- char_count(data)
data$n_word <- word_count(data)
data$n_stop <- stop_word_count(data,stop_word)
data$per_stop <- stop_word_percentage(data)
# Add sentiment score
data$senti_score <- senti(data)
# Add tf_idf
ans_tfidf <- by(data, data$question_title, tf_idf_score)
# Global variables
data <- tbl_df(read_csv("~/dsR/final/data/current_event.csv")) %>% na.omit()
#data <- data[1:50, ]
# Clean entire datum
#data <- full_clean(data)
#data <- subset(data, data$ans_upvote_num != 0)
#data <- text_filter(data)
#Reorder the data
data <- data[order(data$question_title),]
# Get stop words
data$question_combined <- paste(data$question_title, data$question_detail)
document <- c(unique(data$question_combined),unique(data$ans))
stop_word <- get_stop_word(document)
stop_word <- unique(c(stop_word, toTrad(stopwordsCN())))
# Add response time
data$response_time <- time_transform(data)
# Add segmented questions and answers
data$ans_seg <- sapply(data$ans, function(x) paste(filter_segment(seg_worker[x], stop_word), collapse = ' '))
data$ans_seg_vec <- sapply(data$ans, function(x) filter_segment(seg_worker[x], stop_word))
data$q_seg <- sapply(data$question_combined, function(x) paste(filter_segment(seg_worker[x], stop_word), collapse = ' '))
# Add number of characters, words, and percentage of stop words
data$n_char <- char_count(data)
data$n_word <- word_count(data)
data$n_stop <- stop_word_count(data,stop_word)
data$per_stop <- stop_word_percentage(data)
# Add sentiment score
data$senti_score <- senti(data)
library(readr)
library(dplyr)
library(jiebaR)
library(tidytext)
library(fpc)
library(cluster)
library(rJava)
library(tm)
library(SnowballC)
library(slam)
library(XML)
library(RCurl)
library(Matrix)
library(tmcn)
library(Rwordseg)
source('~/dsR/final/script/zhihu_utility.R')
source('~/dsR/final/script/zhihu_count.R')
source('~/dsR/final/script/zhihu_senti.R')
source('~/dsR/final/script/zhihu_tfidf_score.R')
#source('~/dsR/final/script/zhihu_tf_idf.R')
#source('~/dsR/final/script/zhihu_cluster.R')
# Global variables
data <- tbl_df(read_csv("~/dsR/final/data/current_event.csv")) %>% na.omit()
#data <- data[1:50, ]
# Clean entire datum
#data <- full_clean(data)
#data <- subset(data, data$ans_upvote_num != 0)
#data <- text_filter(data)
#Reorder the data
data <- data[order(data$question_title),]
# Get stop words
data$question_combined <- paste(data$question_title, data$question_detail)
document <- c(unique(data$question_combined),unique(data$ans))
stop_word <- get_stop_word(document)
stop_word <- unique(c(stop_word, toTrad(stopwordsCN())))
# Add response time
data$response_time <- time_transform(data)
# Add segmented questions and answers
data$ans_seg <- sapply(data$ans, function(x) paste(filter_segment(seg_worker[x], stop_word), collapse = ' '))
data$ans_seg_vec <- sapply(data$ans, function(x) filter_segment(seg_worker[x], stop_word))
data$q_seg <- sapply(data$question_combined, function(x) paste(filter_segment(seg_worker[x], stop_word), collapse = ' '))
# Add number of characters, words, and percentage of stop words
data$n_char <- char_count(data)
data$n_word <- word_count(data)
data$n_stop <- stop_word_count(data,stop_word)
data$per_stop <- stop_word_percentage(data)
# Add sentiment score
data$senti_score <- senti(data)
# Add tf_idf
ans_tfidf <- by(data, data$question_title, tf_idf_score)
data$ans_tfidf <- unlist(ans_tfidf)
# Add cluster
#data <- get_cluster_feature(data)
head(data,20)
#put the data to the df
current_events <- data
View(current_events)
data <- get_cluster_feature(data)
source('~/dsR/final/script/zhihu_cluster.R')
data <- get_cluster_feature(data)
testset <- take_sample(data)
o
ans_quality <- by(data, data$question_title, get_ans_quality)
data$ans_quality <- unlist(ans_quality)
head(data,20)
testset <- take_sample(data)
testset <- take_sample(data)
source('~/dsR/final/script/zhihu_utility.R')
testset <- take_sample(data)
source('~/dsR/final/script/zhihu_utility.R')
#put the data to the df
current_events <- data
testset <- take_sample(data)
# Add answer quality
ans_quality <- by(data, data$question_title, get_ans_quality)
data$quality <- unlist(ans_quality)
head(data,20)
testset <- take_sample(data)
trainset <- anti_join(data,testset)
data <- subset(data, data$ans_upvote_num != 0)
# Add answer quality
ans_quality <- by(data, data$question_title, get_ans_quality)
data$quality <- unlist(ans_quality)
head(data,20)
testset <- take_sample(data)
trainset <- anti_join(data,testset)
library(readr)
library(dplyr)
library(jiebaR)
library(tidytext)
library(fpc)
library(cluster)
library(rJava)
library(tm)
library(SnowballC)
library(slam)
library(XML)
library(RCurl)
library(Matrix)
library(tmcn)
library(Rwordseg)
source('~/dsR/final/script/zhihu_utility.R')
source('~/dsR/final/script/zhihu_count.R')
source('~/dsR/final/script/zhihu_senti.R')
source('~/dsR/final/script/zhihu_tfidf_score.R')
#source('~/dsR/final/script/zhihu_tf_idf.R')
source('~/dsR/final/script/zhihu_cluster.R')
# Global variables
data <- tbl_df(read_csv("~/dsR/final/data/current_event.csv")) %>% na.omit()
#data <- data[1:50, ]
# Clean entire datum
data <- full_clean(data)
#data <- subset(data, data$ans_upvote_num != 0)
#data <- text_filter(data)
#Reorder the data
data <- data[order(data$question_title),]
# Get stop words
data$question_combined <- paste(data$question_title, data$question_detail)
document <- c(unique(data$question_combined),unique(data$ans))
stop_word <- get_stop_word(document)
stop_word <- unique(c(stop_word, toTrad(stopwordsCN())))
# Add response time
data$response_time <- time_transform(data)
# Add segmented questions and answers
data$ans_seg <- sapply(data$ans, function(x) paste(filter_segment(seg_worker[x], stop_word), collapse = ' '))
data$ans_seg_vec <- sapply(data$ans, function(x) filter_segment(seg_worker[x], stop_word))
data$q_seg <- sapply(data$question_combined, function(x) paste(filter_segment(seg_worker[x], stop_word), collapse = ' '))
# Add number of characters, words, and percentage of stop words
data$n_char <- char_count(data)
data$n_word <- word_count(data)
data$n_stop <- stop_word_count(data,stop_word)
data$per_stop <- stop_word_percentage(data)
# Add sentiment score
data$senti_score <- senti(data)
# Add tf_idf
ans_tfidf <- by(data, data$question_title, tf_idf_score)
library(readr)
library(dplyr)
library(jiebaR)
library(tidytext)
library(fpc)
library(cluster)
library(rJava)
library(tm)
library(SnowballC)
library(slam)
library(XML)
library(RCurl)
library(Matrix)
library(tmcn)
library(Rwordseg)
source('~/dsR/final/script/zhihu_utility.R')
source('~/dsR/final/script/zhihu_count.R')
source('~/dsR/final/script/zhihu_senti.R')
source('~/dsR/final/script/zhihu_tfidf_score.R')
#source('~/dsR/final/script/zhihu_tf_idf.R')
source('~/dsR/final/script/zhihu_cluster.R')
# Global variables
data <- tbl_df(read_csv("~/dsR/final/data/current_event.csv")) %>% na.omit()
#data <- data[1:50, ]
# Clean entire datum
#data <- full_clean(data)
#data <- subset(data, data$ans_upvote_num != 0)
data <- text_filter(data)
#Reorder the data
data <- data[order(data$question_title),]
# Get stop words
data$question_combined <- paste(data$question_title, data$question_detail)
document <- c(unique(data$question_combined),unique(data$ans))
stop_word <- get_stop_word(document)
stop_word <- unique(c(stop_word, toTrad(stopwordsCN())))
# Add response time
data$response_time <- time_transform(data)
# Add segmented questions and answers
data$ans_seg <- sapply(data$ans, function(x) paste(filter_segment(seg_worker[x], stop_word), collapse = ' '))
data$ans_seg_vec <- sapply(data$ans, function(x) filter_segment(seg_worker[x], stop_word))
data$q_seg <- sapply(data$question_combined, function(x) paste(filter_segment(seg_worker[x], stop_word), collapse = ' '))
# Add number of characters, words, and percentage of stop words
data$n_char <- char_count(data)
data$n_word <- word_count(data)
data$n_stop <- stop_word_count(data,stop_word)
data$per_stop <- stop_word_percentage(data)
# Add sentiment score
data$senti_score <- senti(data)
# Add tf_idf
ans_tfidf <- by(data, data$question_title, tf_idf_score)
library(readr)
library(dplyr)
library(jiebaR)
library(tidytext)
library(fpc)
library(cluster)
library(rJava)
library(tm)
library(SnowballC)
library(slam)
library(XML)
library(RCurl)
library(Matrix)
library(tmcn)
library(Rwordseg)
source('~/dsR/final/script/zhihu_utility.R')
source('~/dsR/final/script/zhihu_count.R')
source('~/dsR/final/script/zhihu_senti.R')
source('~/dsR/final/script/zhihu_tfidf_score.R')
#source('~/dsR/final/script/zhihu_tf_idf.R')
source('~/dsR/final/script/zhihu_cluster.R')
# Global variables
data <- tbl_df(read_csv("~/dsR/final/data/current_event.csv")) %>% na.omit()
#data <- data[1:50, ]
# Clean entire datum
#data <- full_clean(data)
#data <- subset(data, data$ans_upvote_num != 0)
#data <- text_filter(data)
#Reorder the data
data <- data[order(data$question_title),]
# Get stop words
data$question_combined <- paste(data$question_title, data$question_detail)
document <- c(unique(data$question_combined),unique(data$ans))
stop_word <- get_stop_word(document)
stop_word <- unique(c(stop_word, toTrad(stopwordsCN())))
# Add response time
data$response_time <- time_transform(data)
# Add segmented questions and answers
data$ans_seg <- sapply(data$ans, function(x) paste(filter_segment(seg_worker[x], stop_word), collapse = ' '))
data$ans_seg_vec <- sapply(data$ans, function(x) filter_segment(seg_worker[x], stop_word))
data$q_seg <- sapply(data$question_combined, function(x) paste(filter_segment(seg_worker[x], stop_word), collapse = ' '))
# Add number of characters, words, and percentage of stop words
data$n_char <- char_count(data)
data$n_word <- word_count(data)
data$n_stop <- stop_word_count(data,stop_word)
data$per_stop <- stop_word_percentage(data)
# Add sentiment score
data$senti_score <- senti(data)
library(readr)
library(dplyr)
library(jiebaR)
library(tidytext)
library(fpc)
library(cluster)
library(rJava)
library(tm)
library(SnowballC)
library(slam)
library(XML)
library(RCurl)
library(Matrix)
library(tmcn)
library(Rwordseg)
source('~/dsR/final/script/zhihu_utility.R')
source('~/dsR/final/script/zhihu_count.R')
source('~/dsR/final/script/zhihu_senti.R')
source('~/dsR/final/script/zhihu_tfidf_score.R')
#source('~/dsR/final/script/zhihu_tf_idf.R')
source('~/dsR/final/script/zhihu_cluster.R')
# Global variables
data <- tbl_df(read_csv("~/dsR/final/data/current_event.csv")) %>% na.omit()
#data <- data[1:50, ]
# Clean entire datum
data <- full_clean(data)
#data <- subset(data, data$ans_upvote_num != 0)
#data <- text_filter(data)
#Reorder the data
data <- data[order(data$question_title),]
# Get stop words
data$question_combined <- paste(data$question_title, data$question_detail)
document <- c(unique(data$question_combined),unique(data$ans))
stop_word <- get_stop_word(document)
stop_word <- unique(c(stop_word, toTrad(stopwordsCN())))
# Add response time
data$response_time <- time_transform(data)
# Add segmented questions and answers
data$ans_seg <- sapply(data$ans, function(x) paste(filter_segment(seg_worker[x], stop_word), collapse = ' '))
data$ans_seg_vec <- sapply(data$ans, function(x) filter_segment(seg_worker[x], stop_word))
#data$q_seg <- sapply(data$question_combined, function(x) paste(filter_segment(seg_worker[x], stop_word), collapse = ' '))
# Add number of characters, words, and percentage of stop words
data$n_char <- char_count(data)
data$n_word <- word_count(data)
data$n_stop <- stop_word_count(data,stop_word)
data$per_stop <- stop_word_percentage(data)
# Add sentiment score
data$senti_score <- senti(data)
# Add tf_idf
ans_tfidf <- by(data, data$question_title, tf_idf_score)
library(readr)
library(dplyr)
library(jiebaR)
library(tidytext)
library(fpc)
library(cluster)
library(rJava)
library(tm)
library(SnowballC)
library(slam)
library(XML)
library(RCurl)
library(Matrix)
library(tmcn)
library(Rwordseg)
source('~/dsR/final/script/zhihu_utility.R')
source('~/dsR/final/script/zhihu_count.R')
source('~/dsR/final/script/zhihu_senti.R')
source('~/dsR/final/script/zhihu_tfidf_score.R')
#source('~/dsR/final/script/zhihu_tf_idf.R')
source('~/dsR/final/script/zhihu_cluster.R')
# Global variables
data <- tbl_df(read_csv("~/dsR/final/data/current_event.csv")) %>% na.omit()
#data <- data[1:50, ]
# Clean entire datum
#data <- full_clean(data)
#data <- subset(data, data$ans_upvote_num != 0)
data <- text_filter(data)
#Reorder the data
data <- data[order(data$question_title),]
# Get stop words
data$question_combined <- paste(data$question_title, data$question_detail)
document <- c(unique(data$question_combined),unique(data$ans))
stop_word <- get_stop_word(document)
stop_word <- unique(c(stop_word, toTrad(stopwordsCN())))
# Add response time
data$response_time <- time_transform(data)
# Add segmented questions and answers
data$ans_seg <- sapply(data$ans, function(x) paste(filter_segment(seg_worker[x], stop_word), collapse = ' '))
data$ans_seg_vec <- sapply(data$ans, function(x) filter_segment(seg_worker[x], stop_word))
#data$q_seg <- sapply(data$question_combined, function(x) paste(filter_segment(seg_worker[x], stop_word), collapse = ' '))
# Add number of characters, words, and percentage of stop words
data$n_char <- char_count(data)
data$n_word <- word_count(data)
data$n_stop <- stop_word_count(data,stop_word)
data$per_stop <- stop_word_percentage(data)
# Add sentiment score
data$senti_score <- senti(data)
# Add tf_idf
ans_tfidf <- by(data, data$question_title, tf_idf_score)
library(readr)
library(dplyr)
library(jiebaR)
library(tidytext)
library(fpc)
library(cluster)
library(rJava)
library(tm)
library(SnowballC)
library(slam)
library(XML)
library(RCurl)
library(Matrix)
library(tmcn)
library(Rwordseg)
source('~/dsR/final/script/zhihu_utility.R')
source('~/dsR/final/script/zhihu_count.R')
source('~/dsR/final/script/zhihu_senti.R')
source('~/dsR/final/script/zhihu_tfidf_score.R')
#source('~/dsR/final/script/zhihu_tf_idf.R')
source('~/dsR/final/script/zhihu_cluster.R')
# Global variables
data <- tbl_df(read_csv("~/dsR/final/data/current_event.csv")) %>% na.omit()
#data <- data[1:50, ]
# Clean entire datum
#data <- full_clean(data)
#data <- subset(data, data$ans_upvote_num != 0)
#data <- text_filter(data)
#Reorder the data
data <- data[order(data$question_title),]
# Get stop words
data$question_combined <- paste(data$question_title, data$question_detail)
document <- c(unique(data$question_combined),unique(data$ans))
stop_word <- get_stop_word(document)
stop_word <- unique(c(stop_word, toTrad(stopwordsCN())))
# Add response time
data$response_time <- time_transform(data)
# Add segmented questions and answers
data$ans_seg <- sapply(data$ans, function(x) paste(filter_segment(seg_worker[x], stop_word), collapse = ' '))
data$ans_seg_vec <- sapply(data$ans, function(x) filter_segment(seg_worker[x], stop_word))
#data$q_seg <- sapply(data$question_combined, function(x) paste(filter_segment(seg_worker[x], stop_word), collapse = ' '))
# Add number of characters, words, and percentage of stop words
data$n_char <- char_count(data)
data$n_word <- word_count(data)
data$n_stop <- stop_word_count(data,stop_word)
data$per_stop <- stop_word_percentage(data)
# Add sentiment score
data$senti_score <- senti(data)
# Add tf_idf
ans_tfidf <- by(data, data$question_title, tf_idf_score)
